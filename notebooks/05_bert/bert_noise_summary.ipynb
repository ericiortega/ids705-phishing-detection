{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5bd566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load all results\n",
    "metrics = []\n",
    "\n",
    "for level in [0, 5, 10, 15, 30]:\n",
    "    tag = \"clean\" if level == 0 else f\"noise_{level}\"\n",
    "    with open(f\"../../results/metrics_{tag}.json\") as f:\n",
    "        result = json.load(f)\n",
    "        result[\"noise_level\"] = level\n",
    "        metrics.append(result)\n",
    "\n",
    "# convert to dataframe\n",
    "df = pd.DataFrame(metrics).sort_values(\"noise_level\")\n",
    "\n",
    "# plot f1 score\n",
    "plt.plot(df[\"noise_level\"], df[\"f1_phishing\"], marker=\"o\")\n",
    "plt.title(\"F1 Score vs Noise Level\")\n",
    "plt.xlabel(\"Noise Level (%)\")\n",
    "plt.ylabel(\"F1 Score (Phishing)\")\n",
    "plt.ylim(0.7, 1.05)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# plot accuracy\n",
    "plt.plot(df[\"noise_level\"], df[\"accuracy\"], marker=\"o\")\n",
    "plt.title(\"Accuracy vs Noise Level\")\n",
    "plt.xlabel(\"Noise Level (%)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0.7, 1.05)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# display full table\n",
    "df[[\"noise_level\", \"accuracy\", \"f1_phishing\", \"precision\", \"recall\"]]\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
